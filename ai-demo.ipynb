{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c53e5c8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sendto ('127.0.0.1', 7000): daaaaaasdasd\n"
     ]
    },
    {
     "ename": "ConnectionResetError",
     "evalue": "[WinError 10054] 遠端主機已強制關閉一個現存的連線。",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mConnectionResetError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20688/314748848.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msendto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mserver_addr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0mindata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maddr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecvfrom\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1024\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'recvfrom '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maddr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m': '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mindata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mConnectionResetError\u001b[0m: [WinError 10054] 遠端主機已強制關閉一個現存的連線。"
     ]
    }
   ],
   "source": [
    "import socket\n",
    "\n",
    "HOST = '127.0.0.1'\n",
    "PORT = 8000\n",
    "server_addr = (HOST, PORT)\n",
    "\n",
    "s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)\n",
    "\n",
    "outdata = input('please input message: ')\n",
    "print('sendto ' + str(server_addr) + ': ' + outdata)\n",
    "s.sendto(outdata.encode(), server_addr)\n",
    "\n",
    "indata, addr = s.recvfrom(1024)\n",
    "print('recvfrom ' + str(addr) + ': ' + indata.decode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90b959fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "server start at: 0.0.0.0:8026\n",
      "wait for connection...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\andy4/.cache\\torch\\hub\\ultralytics_yolov5_master\n",
      "YOLOv5  2022-9-21 Python-3.9.7 torch-1.12.1+cu113 CUDA:0 (NVIDIA GeForce RTX 2060, 6144MiB)\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 157 layers, 7012822 parameters, 0 gradients\n",
      "Adding AutoShape... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recvfrom ('192.168.162.12', 38358): 0x332e921d92\n",
      "outdata = ''\n",
      "{\"message\":\"ok\"}\n",
      "recvfrom ('192.168.162.12', 37325): 0x332e921d92\n",
      "outdata = ''\n",
      "recvfrom ('192.168.162.12', 57584): 0xa21f4521d9\n",
      "outdata = ''\n",
      "recvfrom ('192.168.162.12', 56329): 0xa21f4521d9\n",
      "outdata = ''\n",
      "outdata = ''\n",
      "{\"message\":\"ok\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-10:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\andy4\\anaconda3\\lib\\threading.py\", line 973, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\andy4\\anaconda3\\lib\\threading.py\", line 910, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Users\\andy4\\AppData\\Local\\Temp/ipykernel_26484/693457932.py\", line 35, in listen\n",
      "OSError: [WinError 10038] 嘗試操作的對象不是通訊端。\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Close Socket\n"
     ]
    }
   ],
   "source": [
    "# streaming yolov5 辨識有無安全帽\n",
    "\n",
    "import math\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "from IPython.display import clear_output\n",
    "import socket\n",
    "import threading\n",
    "import requests\n",
    "\n",
    "class SocketServer:\n",
    "    # 建構式\n",
    "    def __init__(self, host, port):\n",
    "        # Socket Setting\n",
    "        #HOST = '127.0.0.1'\n",
    "        #PORT = 8000\n",
    "        self.s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)\n",
    "        self.s.bind((host, port))\n",
    "        self.signal = False\n",
    "        print('server start at: %s:%s' % (host, port))\n",
    "        print('wait for connection...')\n",
    "    def listen(self):\n",
    "        while not self.signal:\n",
    "            global socket_data\n",
    "            global outdata\n",
    "            indata, addr = self.s.recvfrom(1024)\n",
    "            print('recvfrom ' + str(addr) + ': ' + indata.decode())\n",
    "            outdata = ''\n",
    "            socket_data = indata.decode()\n",
    "            \n",
    "            while outdata == '':\n",
    "                print(f'{outdata = }')\n",
    "                time.sleep(0.5)\n",
    "                pass\n",
    "            \n",
    "            self.s.sendto(outdata.encode(), addr)\n",
    "    def exit(self):\n",
    "        self.s.close()\n",
    "        self.signal = True\n",
    "        print(\"Close Socket\")\n",
    "        \n",
    "\n",
    "socket_data = \"\"    \n",
    "outdata = ''\n",
    "socketServer = SocketServer(\"0.0.0.0\", 8026)\n",
    "t = threading.Thread(target=socketServer.listen)\n",
    "t.start()\n",
    "\n",
    "\n",
    "os.chdir(\"C:\\\\Users\\\\andy4\\\\yolov5\")\n",
    "\n",
    "# 載入自行訓練的 YOLOv5 模型\n",
    "model = torch.hub.load('ultralytics/yolov5', 'custom', \n",
    "                       path='E:\\\\helmet_detect\\\\all_helmet_data\\\\results\\\\head-2022-10-18-yolov5s-new\\\\head-2022-10-18-yolov5s-new.pt')\n",
    "\n",
    "model2 = torch.load('Resnet18_98199.pt')\n",
    "# 設定 IoU 門檻值\n",
    "model.iou = 0.5\n",
    "# 設定信心門檻值\n",
    "model.conf = 0.5\n",
    "\n",
    "# 影像來源\n",
    "#img_path = \"http://video.itri.go:1010/video/store\" # 串流網址\n",
    "img_path = 0 # 筆電鏡頭\n",
    "\n",
    "cap = cv2.VideoCapture(img_path)\n",
    "\n",
    "correct = 0\n",
    "y_true = []\n",
    "y_pred = []\n",
    "model2.eval()\n",
    "\n",
    "transform = transforms.Compose([transforms.Resize([224, 224]),transforms.ToTensor()])\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "a = 0\n",
    "\n",
    "while(True): # socket.listen\n",
    "    if 1>0: # receive socket\n",
    "        \n",
    "        #if socket_data != \"\":\n",
    "        #     a = 1\n",
    "        \n",
    "        safe_counter = 0\n",
    "        for ten in range(10):\n",
    "            ret, img = cap.read()\n",
    "\n",
    "            cv2.imwrite('output_temp.png', img)\n",
    "\n",
    "            # 進行物件偵測\n",
    "            results = model('output_temp.png')\n",
    "\n",
    "            # return the predictions as a pandas dataframe\n",
    "            bbox_df = results.pandas().xyxy[0]\n",
    "\n",
    "            img = cv2.imread('output_temp.png')\n",
    "\n",
    "            max_area = 0\n",
    "\n",
    "            main_xmin = 0\n",
    "            main_xmax = 0\n",
    "            main_ymin = 0\n",
    "            main_ymax = 0\n",
    "\n",
    "            main_crop_img = np.zeros((10,10),dtype=int)\n",
    "\n",
    "            for bbox_number in range(len(bbox_df)):\n",
    "\n",
    "                # 偵測到的bounding box\n",
    "                xmin = int(bbox_df['xmin'][bbox_number])\n",
    "                ymin = int(bbox_df['ymin'][bbox_number])\n",
    "                xmax = int(bbox_df['xmax'][bbox_number])\n",
    "                ymax = int(bbox_df['ymax'][bbox_number])\n",
    "                confidence = str(round(bbox_df['confidence'][bbox_number],2))\n",
    "\n",
    "                if ( (xmax-xmin)*(ymax-ymin) ) > max_area:\n",
    "                    max_area = (xmax-xmin)*(ymax-ymin)\n",
    "                    main_xmin = xmin\n",
    "                    main_xmax = xmax\n",
    "                    main_ymin = ymin\n",
    "                    main_ymax = ymax\n",
    "\n",
    "            main_crop_img = img[main_ymin:main_ymax, main_xmin:main_xmax].copy()\n",
    "            # 已經切好的暫存img\n",
    "            cv2.imwrite('detected_results_temp.png', main_crop_img)\n",
    "\n",
    "            img_2 = Image.open('detected_results_temp.png').convert('RGB')\n",
    "\n",
    "            image_tensor = transform(img_2)\n",
    "            images = image_tensor.unsqueeze(0)\n",
    "            images = images.to(device)\n",
    "\n",
    "            outputs = model2(images)\n",
    "\n",
    "            _ = []\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            y_pred = int(predicted.cpu().numpy())\n",
    "\n",
    "            label_0 = 1/(1 + math.exp(float(outputs.squeeze().tolist()[0])))\n",
    "            label_1 = 1/(1 + math.exp(float(outputs.squeeze().tolist()[1])))\n",
    "\n",
    "            if label_0 > label_1:\n",
    "                res_result = str(round((label_0),2))\n",
    "            else:\n",
    "                res_result = str(round((label_1),2))\n",
    "\n",
    "            if y_pred == 1:\n",
    "                safe_counter = safe_counter + 1\n",
    "                cv2.rectangle(img, (main_xmin, main_ymin), (main_xmax, main_ymax), (0, 255, 0), 1)\n",
    "                cv2.putText(img, \"Helmet \" + str(res_result), (main_xmin-5, main_ymin-5), cv2.FONT_HERSHEY_SIMPLEX,0.8, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "            else:\n",
    "                cv2.rectangle(img, (main_xmin, main_ymin), (main_xmax, main_ymax), (0, 0, 255), 2)\n",
    "                cv2.putText(img, \"UnHelmet \" + str(res_result), (main_xmin-5, main_ymin-5), cv2.FONT_HERSHEY_SIMPLEX,0.8, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "                cv2.rectangle(img, (505,0), (640,30), (0,0,255), cv2.FILLED) # text background\n",
    "                cv2.putText(img, \"Detected\", (520, 25), cv2.FONT_HERSHEY_DUPLEX,0.8, (255, 255, 255), 1, cv2.LINE_AA)\n",
    "\n",
    "            #cv2.putText(fir_img, \"Yolo Result\", (5, 30), cv2.FONT_HERSHEY_DUPLEX,0.8, (255, 0, 0), 1, cv2.LINE_AA)\n",
    "            cv2.putText(img, \"ResNet Result\", (5, 30), cv2.FONT_HERSHEY_DUPLEX,0.8, (255, 0, 0), 1, cv2.LINE_AA)\n",
    "\n",
    "\n",
    "            #cv2.imshow('first_stage_frame', img)\n",
    "            cv2.imshow('second stage frame',img)\n",
    "            #cv2.imshow('main_detect', main_crop_img)\n",
    "\n",
    "            # 若按下 q 鍵則離開迴圈\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                a=1\n",
    "                \n",
    "        if safe_counter < 5:\n",
    "            outdata = 'notpass'\n",
    "            \n",
    "            if not socket_data == '':\n",
    "                cv2.imwrite('hi.png', img)\n",
    "                url = f\"http://handler.tsmc.n0b.me/api/v1/alert?rfid={socket_data}\"\n",
    "                files = {'file': open('hi.png', 'rb')}\n",
    "                response = requests.post(url, files=files)\n",
    "                try:\n",
    "                    print(response.text)           \n",
    "                except requests.exceptions.RequestException:\n",
    "                    print(response.text)\n",
    "                    \n",
    "            socket_data = ''\n",
    "            \n",
    "        else:\n",
    "            outdata = 'pass'\n",
    "            socket_data = ''\n",
    "            # 8\n",
    "            \n",
    "        if a == 1:\n",
    "            socketServer.exit()\n",
    "            break\n",
    "# 釋放攝影機\n",
    "cap.release()\n",
    "\n",
    "# 關閉所有 OpenCV 視窗\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56e7159b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\andy4/.cache\\torch\\hub\\ultralytics_yolov5_master\n",
      "YOLOv5  2022-9-21 Python-3.9.7 torch-1.12.1+cu113 CUDA:0 (NVIDIA GeForce RTX 2060, 6144MiB)\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 157 layers, 7012822 parameters, 0 gradients\n",
      "Adding AutoShape... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "activate\n",
      "{\"message\":\"ok\"}\n",
      "activate\n",
      "activate\n",
      "activate\n",
      "activate\n",
      "activate\n",
      "activate\n",
      "activate\n",
      "activate\n",
      "activate\n",
      "activate\n",
      "activate\n",
      "activate\n",
      "activate\n",
      "activate\n",
      "activate\n",
      "activate\n",
      "activate\n",
      "activate\n",
      "activate\n",
      "activate\n"
     ]
    }
   ],
   "source": [
    "# streaming yolov5 辨識有無安全帽\n",
    "\n",
    "import math\n",
    "import os\n",
    "import sys\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "from IPython.display import clear_output\n",
    "import requests\n",
    "\n",
    "\n",
    "os.chdir(\"C:\\\\Users\\\\andy4\\\\yolov5\")\n",
    "\n",
    "# 載入自行訓練的 YOLOv5 模型\n",
    "model = torch.hub.load('ultralytics/yolov5', 'custom', \n",
    "                       path='E:\\\\helmet_detect\\\\all_helmet_data\\\\results\\\\head-2022-10-18-yolov5s-new\\\\head-2022-10-18-yolov5s-new.pt')\n",
    "\n",
    "model2 = torch.load('Resnet18_98199.pt')\n",
    "# 設定 IoU 門檻值\n",
    "model.iou = 0.5\n",
    "# 設定信心門檻值\n",
    "model.conf = 0.5\n",
    "\n",
    "# 影像來源\n",
    "#img_path = \"http://video.itri.go:1010/video/store\" # 串流網址\n",
    "img_path = 0 # 筆電鏡頭\n",
    "\n",
    "cap = cv2.VideoCapture(img_path)\n",
    "\n",
    "correct = 0\n",
    "y_true = []\n",
    "y_pred = []\n",
    "model2.eval()\n",
    "\n",
    "transform = transforms.Compose([transforms.Resize([224, 224]),transforms.ToTensor()])\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "flag_sum = 0\n",
    "\n",
    "\n",
    "flag = 1\n",
    "\n",
    "while(True):\n",
    "    \n",
    "    ret, img = cap.read()\n",
    "    \n",
    "    red_flag = 0\n",
    "    \n",
    "    cv2.imwrite('output_temp.png', img)\n",
    "    \n",
    "    # 進行物件偵測\n",
    "    results = model('output_temp.png')\n",
    "    \n",
    "    # return the predictions as a pandas dataframe\n",
    "    bbox_df = results.pandas().xyxy[0]\n",
    "\n",
    "    img = cv2.imread('output_temp.png')\n",
    "    \n",
    "    sec_img = img.copy()\n",
    "\n",
    "    for bbox_number in range(len(bbox_df)):\n",
    "    \n",
    "        # 偵測到的bounding box\n",
    "        xmin = int(bbox_df['xmin'][bbox_number])\n",
    "        ymin = int(bbox_df['ymin'][bbox_number])\n",
    "        xmax = int(bbox_df['xmax'][bbox_number])\n",
    "        ymax = int(bbox_df['ymax'][bbox_number])\n",
    "        confidence = str(round(bbox_df['confidence'][bbox_number],2))\n",
    "\n",
    "        crop_img = []\n",
    "        crop_img = img[ymin:ymax, xmin:xmax].copy()\n",
    "        \n",
    "        cv2.rectangle(img, (xmin, ymin), (xmax, ymax), (0, 255, 0), 2)\n",
    "        cv2.putText(img, \"head \" + str(confidence), (xmin-5, ymin-5), cv2.FONT_HERSHEY_DUPLEX,0.8, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "        \n",
    "        # 已經切好的暫存img\n",
    "        cv2.imwrite('detected_results_temp.png', crop_img)\n",
    "        \n",
    "        img_2 = Image.open('detected_results_temp.png').convert('RGB')\n",
    "        \n",
    "        image_tensor = transform(img_2)\n",
    "        images = image_tensor.unsqueeze(0)\n",
    "        images = images.to(device)\n",
    "        \n",
    "        outputs = model2(images)\n",
    "        \n",
    "        _ = []\n",
    "        \n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        y_pred = int(predicted.cpu().numpy())\n",
    "        \n",
    "        label_0 = 1/(1 + math.exp(float(outputs.squeeze().tolist()[0])))\n",
    "        label_1 = 1/(1 + math.exp(float(outputs.squeeze().tolist()[1])))\n",
    "        \n",
    "        if label_0 > label_1:\n",
    "            res_result = str(round((label_0),2))\n",
    "        else:\n",
    "            res_result = str(round((label_1),2))\n",
    "        \n",
    "        if y_pred == 1:\n",
    "            cv2.rectangle(sec_img, (xmin, ymin), (xmax, ymax), (0, 255, 0), 1)\n",
    "            cv2.putText(sec_img, \"Helmet \" + str(res_result), (xmin-5, ymin-5), cv2.FONT_HERSHEY_SIMPLEX,0.8, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "        else:\n",
    "            red_flag = 1\n",
    "            cv2.rectangle(sec_img, (xmin, ymin), (xmax, ymax), (0, 0, 255), 2)\n",
    "            cv2.putText(sec_img, \"UnHelmet \" + str(res_result), (xmin-5, ymin-5), cv2.FONT_HERSHEY_SIMPLEX,0.8, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "            cv2.rectangle(sec_img, (500,0), (640,30), (0,0,255), cv2.FILLED) # text background\n",
    "            cv2.putText(sec_img, \"Detected\", (520, 25), cv2.FONT_HERSHEY_DUPLEX,0.8, (255, 255, 255), 1, cv2.LINE_AA)\n",
    "        \n",
    "        #print('predict: ', y_pred)\n",
    "    \n",
    "    if red_flag == 0:\n",
    "        flag_sum = 0\n",
    "    else:\n",
    "        flag_sum = flag_sum + 1\n",
    "        \n",
    "    if flag_sum > 100:\n",
    "        flag_sum = 0\n",
    "        print(\"activate\")\n",
    "        # call API (send sec_img)\n",
    "        if flag == 1:\n",
    "            cv2.imwrite('hi.png', sec_img)\n",
    "            url = \"http://handler.tsmc.n0b.me/api/v1/alert\"\n",
    "            files = {'file': open('hi.png', 'rb')}\n",
    "            response = requests.post(url, files=files)\n",
    "            flag = 0\n",
    "            try:\n",
    "                print(response.text)           \n",
    "            except requests.exceptions.RequestException:\n",
    "                print(response.text)\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "    cv2.putText(img, \"Yolo Result\", (5, 30), cv2.FONT_HERSHEY_DUPLEX,0.8, (255, 0, 0), 1, cv2.LINE_AA)\n",
    "    cv2.putText(sec_img, \"ResNet Result\", (5, 30), cv2.FONT_HERSHEY_DUPLEX,0.8, (255, 0, 0), 1, cv2.LINE_AA)\n",
    "    \n",
    "        \n",
    "    cv2.imshow('first_stage_frame', img)\n",
    "    cv2.imshow('second stage frame',sec_img)\n",
    "\n",
    "    # 若按下 q 鍵則離開迴圈\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "        \n",
    "# 釋放攝影機\n",
    "cap.release()\n",
    "\n",
    "# 關閉所有 OpenCV 視窗\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c83f879e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['curl', '-F', \"file=@./fakeimg.png;filename='fake.png'\", \"http://handler.tsmc.n0b.me/api/v1/alert\\\\?rfid='DEADC0DE'\"], returncode=26, stdout=b'', stderr=b'curl: (26) Failed to open/read local data from file/application\\r\\n')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "url = \"http://handler.tsmc.n0b.me/api/v1/alert\\?rfid='DEADC0DE'\"\n",
    "files = {'media': open('test.jpg', 'rb')}\n",
    "requests.post(url, files=files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37546f80",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
